{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN53w-RMPxVK"
      },
      "source": [
        "# Transcribe any audio file with Deepgram!\n",
        "\n",
        "**Make a copy of this notebook into your own drive, and follow the instructions below!** ðŸ¥³ðŸ¥³ðŸ¥³\n",
        "\n",
        "\n",
        "----------------------------\n",
        "\n",
        "# Get started:\n",
        "Running the following three cells will allow you to transcribe any audio you wish. The comments below point out the variables you can manipulate to modify your output as you wish.\n",
        "\n",
        "Before running this notebook, you'll need to have a couple audio files on-hand\n",
        "that you wish to transcribe. Once you have those files in a folder, you should be able to transcribe as you please. Just specify the filepaths as outlined below!\n",
        "\n",
        "And by the way, if you haven't yet signed up for Deepgram, check out this link here: https://dpgr.am/prerecorded-notebook-signup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytg278L-QhAr"
      },
      "source": [
        "# Step 1: Dependencies\n",
        "\n",
        "Run this cell to download all necessary dependencies.\n",
        "\n",
        "Note: You can run a cell by clicking the play button on the left or by clicking on the cell and pressing `shift`+`ENTER` at the same time. (Or `shift` + `return` on Mac)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tDNAqesZNFB4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (2.31.0)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from requests) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from requests) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from requests) (2023.7.22)\n",
            "Collecting future (from ffmpeg-python)\n",
            "  Downloading future-0.18.3.tar.gz (840 kB)\n",
            "     ---------------------------------------- 0.0/840.9 kB ? eta -:--:--\n",
            "     ------------------------- ----------- 583.7/840.9 kB 12.2 MB/s eta 0:00:01\n",
            "     ------------------------------------- 840.9/840.9 kB 13.4 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (pyproject.toml): started\n",
            "  Building wheel for future (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492054 sha256=60afd66dc0f56c4065e85cf1fca6be1a7c9855bd22d2d2d13f8def4497190f2d\n",
            "  Stored in directory: c:\\users\\peter\\appdata\\local\\pip\\cache\\wheels\\bf\\5d\\6a\\2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
            "Successfully built future\n",
            "Installing collected packages: future, ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0 future-0.18.3\n",
            "Requirement already satisfied: deepgram-sdk in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (2.11.0)\n",
            "Requirement already satisfied: aiohttp in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from deepgram-sdk) (3.8.6)\n",
            "Requirement already satisfied: websockets in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from deepgram-sdk) (11.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from aiohttp->deepgram-sdk) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from aiohttp->deepgram-sdk) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from aiohttp->deepgram-sdk) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from aiohttp->deepgram-sdk) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from aiohttp->deepgram-sdk) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from aiohttp->deepgram-sdk) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from aiohttp->deepgram-sdk) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.0 in d:\\projects\\earnings-scribe\\.venv\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp->deepgram-sdk) (3.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install requests ffmpeg-python\n",
        "! pip install deepgram-sdk --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hazx372AOB0v"
      },
      "source": [
        "# Step 2: Upload audio files to this Colab!\n",
        "\n",
        "On the left, you'll see a side-bar with a folder icon. Click that icon, and you'll see a series of folders. This is where you'll upload your audios.\n",
        "\n",
        "You can upload your files directly into this directory by clicking the upload icon in the top left. The icon looks like a sheet of paper with an upwards-pointing arrow on it.\n",
        "\n",
        "Click the upload icon and select the audio file you wish to transcribe. It will take a few moments for the audio to appear, but once it does, move onto Step 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiX4C4vyPKJG"
      },
      "outputs": [],
      "source": [
        "# Have you completed Step 2 above? ðŸ‘€\n",
        "# Do you see your audio file in the folder on the left? ðŸ“‚ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jql62j9YQrai"
      },
      "source": [
        "# Step 3: Transcription\n",
        "\n",
        "Fill in the following variables:\n",
        "\n",
        "\n",
        "* `dg_key` = Your personal Deepgram API key\n",
        "* `MIMETYPE` = the type of audio file you're working with (mp3, mp4, m4a, etc.)\n",
        "* `DIRECTORY` = The name of the folder that contains the audio(s) you wish to transcribe. Note, unless you created a new folder for your audios, the default `'.'` value should be fine. (Or, if you placed your audio file in the default `sample_data` folder, set the value of `DIRECTORY` to `sample_data`.)\n",
        "\n",
        "\n",
        "Now run the cell! (`Shift` + `Enter`)\n",
        "\n",
        "-----------\n",
        "\n",
        "\n",
        "\n",
        "And by the way, if you're already a Deepgram user, and you're getting an error in this cell the most common fixes are:\n",
        "\n",
        "1. You may need to update your installation of the deepgram-sdk.\n",
        "2. You may need to check how many credits you have left in your Deepgram account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlQVesiDOeAf"
      },
      "outputs": [],
      "source": [
        "from deepgram import Deepgram\n",
        "import asyncio, json, os\n",
        "\n",
        "'''\n",
        " Sign up at https://console.deepgram.com/signup\n",
        " to get an API key and 12,000 minutes\n",
        " for free!\n",
        " \n",
        "'''\n",
        "dg_key = 'ðŸ”‘ðŸ”‘ðŸ”‘ Your key here ðŸ”‘ðŸ”‘ðŸ”‘'\n",
        "dg = Deepgram(dg_key)\n",
        "\n",
        "\n",
        "'''\n",
        "The most common audio formats and encodings we support \n",
        "include mp3, mp4, mp2, aac, wav, flac, pcm, m4a, ogg, opus, and webm,\n",
        "So feel free to adjust the `MIMETYPE` variable as needed\n",
        "\n",
        "'''\n",
        "MIMETYPE = 'mp3'\n",
        "\n",
        "#Note: You can use '.' if your audio is in the root\n",
        "DIRECTORY = 'Directory name goes here!'  \n",
        "\n",
        "# Feel free to modify your model's parameters as you wish!\n",
        "options = {\n",
        "    \"punctuate\": True,\n",
        "    \"model\": 'general',\n",
        "    \"tier\": 'enhanced'\n",
        "}\n",
        "\n",
        "#This function is what calls on the model to transcribe\n",
        "def main():\n",
        "    audio_folder = os.listdir(DIRECTORY)\n",
        "    for audio_file in audio_folder:\n",
        "        if audio_file.endswith(MIMETYPE):\n",
        "          with open(f\"{DIRECTORY}/{audio_file}\", \"rb\") as f:\n",
        "              source = {\"buffer\": f, \"mimetype\":'audio/'+MIMETYPE}\n",
        "              res = dg.transcription.sync_prerecorded(source, options)\n",
        "              with open(f\"./{audio_file[:-4]}.json\", \"w\") as transcript:\n",
        "                  json.dump(res, transcript)\n",
        "    return\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecHKxy0q6_fu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "If the cell above succeeds, you should see JSON output file(s) as siblings \n",
        "next to your audio files. Note: There may be a small delay between when \n",
        "the cell finishes running and when the JSON appears. This is normal. Just wait\n",
        "a few moments for the JSONs to appear. It should take less than a minute,\n",
        "depending on the size of your file(s).\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAVvWh7yRAnx"
      },
      "source": [
        "# Step 4: Check out your transcription!\n",
        "\n",
        "The function below parses the output JSON and prints out the pure transcription of one of the files you just transcribed! (Make sure\n",
        "the file you're trying to examine is indeed already loaded into the\n",
        "folder on the left!)\n",
        "\n",
        "**Set the `OUTPUT` variable to the name of the file you wish to see the transcription of.**\n",
        "\n",
        "Then run this cell (`Shift`+`Enter`) to see a sentence-by-sentence transcription of your audio!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7CgWdImOs-E"
      },
      "outputs": [],
      "source": [
        "# Set this variable to the path of the output file you wish to read\n",
        "OUTPUT = 'Pick your favorite output json file :)'\n",
        "\n",
        "\n",
        "# The JSON is loaded with information, but if you just want to read the\n",
        "# transcript, run the code below!\n",
        "def print_transcript(transcription_file):\n",
        "  with open(transcription_file, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "        result = data['results']['channels'][0]['alternatives'][0]['transcript']\n",
        "        result = result.split('.')\n",
        "        for sentence in result:\n",
        "          print(sentence + '.')\n",
        "\n",
        "print_transcript(OUTPUT)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 ('dg_plus_yt': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9ccb4f31e81b19d196bbac066caca5d222f2bb20938f55af05f3ca51e34eca69"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
